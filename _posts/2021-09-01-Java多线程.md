---
title: Java多线程
categories:
  - Java
tags:
location:
abbrlink: '8d0t5y39'
permalink: '8d0t5y39'
date: 2021-09-01 13:42:12
updated: 2021-09-01 13:42:12
---

> 摘要：Java高级之多线程，包括线程的生命周期、创建方式、调度、同步，线程安全，volatile 和 synchronized关键字，线程池，JUC工具类，AQS等。

<!-- more -->

## 多线程

### 书

《深入理解Java虚拟机》
《Java 并发编程的艺术》

### 基本概念

##### 并发 VS 并行

1. 串行：多个任务由同一线程按顺序执行；时间上不重叠；一个队列和一台机器。

2. 并行：多个任务（在多核CPU上，）同一时刻执行；互不干扰；两个队列和两台机器。目前发展方向。

3. 并发：多个任务（在同一CPU上，）在同一时间段内（按时间片轮流）交替执行，逻辑上是同时执行；允许两个任务彼此干扰；两个队列和一台机器。

##### 进程 VS 线程

进程：程序的一次执行（Windows 任务管理器查看 `.exe` 文件的运行）。

线程：进程中的一个执行任务（控制单元），负责当前进程中程序的执行。

<img src="assets/java-runtime-data-areas-jdk1.8.png" alt="Java 运行时数据区域（JDK1.8 之后）" style="zoom:50%;" />

区别：

1. 根本：进程是系统资源分配的基本单位；线程是CPU任务调度和执行的基本单位。
2. 关系：一个进程至少有一个线程，可有多个线程。
3. 内存空间：进程有独立内存空间；所有线程共享堆和方法区（JDK1.8 之后由元空间实现），每个线程有自己的（独享）PC 程序计数器、虚拟机栈和本地方法栈。
4. 开销：进程开销大；线程开销小。
5. 崩溃/健壮：一个进程崩溃后，（在保护模式下）不会对其他进程产生影响；但一个线程崩溃会导致整个进程崩溃。
6. 独立执行：进程有程序运行的入口和出口；但线程不能独立执行，必须依存于进程。

##### 多线程 

优点：
1. 计算机底层：
     - 对单核CPU：减少CPU的空闲时间，提高CPU利用率；防止阻塞；但可能导致频繁的上下文切换；
     - 对多核CPU：充分利用多核CPU的计算能力；减少线程上下文切换的开销；
2. 方便进行业务拆分和建模。

带来的问题：
1. 线程越多占用内存也越大 -> 内存泄漏；
2. 竞争共享资源 -> 线程不安全、死锁；
3. 单核 CPU 中，频繁的上下文切换；

##### 上下文切换

上下文切换：指**CPU控制权**（由一个正在运行的线程）切换到另一个（就绪并等待获取CPU执行权的）线程的过程。

- 保存当前线程的上下文，留待线程下次占用 CPU 时恢复现场,并加载下一个将要占用 CPU 的线程上下文。

原因：
1. 时间片用完，因为 OS 要防止一个线程长时间占用 CPU 导致其他线程饿死；
2. 主动让出 CPU，如调用了 `sleep()、wait()` 等；
3. 调用了阻塞类型的系统中断，如请求 IO、线程被阻塞；
4. 被终止或结束运行。

减少上下文切换可采用：
1. 无锁并发编程；
2. 用 Atomic 类 CAS 算法更新数据，乐观锁可有效减少不必要的锁竞争带来的上下文切换；
3. 使用最少线程：避免创建不需要的线程，（如任务很少，但创建了很多的线程，会造成大量线程处于等待状态）；
4. 协程：在单线程里实现多任务的调度，并维持多个任务间的切换。

##### 守护线程

定义：为所有用户线程提供服务的线程。如：GC 垃圾回收线程，低优先级

```
thread.setDaemon(true);
thread.start();
```

### 生命周期

<img src="assets/640.png" alt="Java 线程状态变迁图" style="zoom: 50%;" />

1. `new`：新建线程对象（仅由 JVM 为其分配内存，并初始化成员变量的值）。
- 调用 `Thread.start()` 启动后进入`ready`；
2. `runnable` 可运行（线程池）：
    - `ready` 就绪/等待运行：（JVM为其创建方法调用栈/VM栈和程序计数器），等待被线程调度选中、等待CPU使用权；
      - （唯一入口）获得CPU资源后进入 `running`；
    - `running` 运行：除非此线程主动放弃 CPU 资源（时间片用完进入ready/阻塞？）或有优先级更高的线程进入，将一直运行、直到结束。
      - 时间片：指将可用的 CPU 时间分配给 Runnable 线程的过程，可基于优先级或等待时间。

3. `blocked` 阻塞：线程因某种原因（）让出 CPU，暂时停止运行，等待获取锁；
   - 解除阻塞（获取到锁）后重新进入`ready`；
4. `waiting` 等待：线程（`runable` ）内 ~~run()~~ 运行语句 `Object.wait()、Thread.join()` 后进入该状态。
   - 当前线程需等待其它线程 notify 通知或中断。
5. `time_waiting` 超时/限期等待：在一定时间后结束等待。`runable` 调用 `Object.wait(long)、Thread.join(long)、Thread.sleep(long)` 进入。
6. `terminted` 终止：线程执行完或因异常退出 run() 方法。

### 线程调度/通信

##### 线程调度

- 抢占式调度模型：指优先让（可运行池中）优先级高的线程占用CPU，处于运行状态的线程会一直运行，直至不得不放弃 CPU。
- 分时调度模型：

##### 线程通信的方式

1. `volatile` 修饰变量：保证所有线程对变量访问的可见性。主要通过读写共享变量来完成隐式通信。
2. `synchronized`：确保多个线程在同一时刻只能有一个处于方法或同步块中。
3. `wait()/notify()` 方法。
4. IO 通信。

##### 导致线程阻塞 VS 唤醒/解除阻塞

唤醒：让线程重新进入就绪状态

1. 等待阻塞（wait）：当前线程需等待其它线程notify通知或中断。(如某项资源就绪/另一个线程放弃排他锁)。
 2. 执行wait()进入此状态：JVM会把该线程放入**等待池**，释放占用的所有资源（包括持有的锁)；
 3. 不会去竞争同步锁，不能自动唤醒（需被其他线程显式唤醒），收到其他线程发出的通知（如调用notify()/notifyAll()）后才会去竞争锁。

4. 超时等待（`time_waiting`）：不分配CPU，超时自动唤醒。

5. 同步阻塞：获取 synchronized 同步锁时，锁被其它线程占用（获取失败)，会放入**锁池**；
 6. 释放同步锁后、锁池中的线程会去竞争同步锁，某个线程竞争成功后会解除阻塞，进入ready。
 7. （等待另一个线程的synchronized 块释放, 或可重入的 synchronized 块里别人调用wait() , 即线程在等待进入临界区）

结束阻塞/恢复线程的时机：

1. 调用sleep()让出占用的CPU资源；sleep()超时
2. 调用yield()让出占用的CPU资源（给优先级相同或更高的线程）进入ready？
3. 调用join()；join()等待线程终止或超时
4. 发出I/O请求；I/O处理完毕
5. 调用suspend()挂起线程（被挂起后不会释放锁，可能与其他线程、主线程产生死锁，已废弃）；resume()恢复线程。

其它唤醒/解除阻塞：

- 因调用wait()、sleep()、join()导致的，可中断线程并抛出InterruptedException；
- 如果线程遇到了IO阻塞，无法唤醒。

##### 常用方法

1. `wait()`：使一个线程处于等待阻塞状态，并释放所持有的（对象的）锁，用于线程交互；
2. `sleep()`：使线程从 running 进入 blocked；一直持有锁，用于暂停执行；静态方法，要处理InterruptedException 异常；
3. `join()`：进入 blocked，直到调用者执行完本身才能执行；
4. `yield()`：使当前线程从 running（不能被其他状态调用）直接变为 ready，让出CPU时间片；静态方法；
5. `notify()`：唤醒一个 wait 状态的线程，由 JVM 决定唤醒哪个线程，与优先级无关；
6. `notityAll()`：唤醒所有wait状态的线程，并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态；

`static Thread Thread.currentThread()`：返回当前线程。在Thread子类中就是this，常用于主线程和 Runnable 实现类。

`boolean isAlive()`：判断线程是否还活着

##### wait() VS sleep() 

两者都可暂停线程执行

1. 所属类：wait() 是 `Object` 类的普通本地方法；sleep() 是 `Thread` 类的静态本地方法。
   1. `wait()` 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁，并让其进入 WAITING 状态。每个对象都拥有对象锁，要操作对应的对象（`Object`）而非当前的线程（`Thread`）；
   2. 因为 `sleep()` 是让当前线程暂停执行，不涉及到对象类，也不需获得对象锁。
2. 释放锁（最大不同）：等待时 wait() 会释放锁，加入等待池；sleep() 一直持有锁，即使有`synchronized` 同步块，其他线程仍不能访问共享数据。
   - sleep() 会让出 CPU 执行时间且强制上下文切换，wait() 则不一定，可能还有机会重新竞争到锁继续执行。
3. ~~依赖~~：wait() 依赖同步器 `synchronized`，而sleep()不依赖。
4. 用途：wait() 常用于线程间交互/通信；sleep() 常用于当前线程休眠或轮询暂停执行操作。
5. 唤醒：wait() 需其它线程调用 `notify()/notifyAll()` 唤醒，或 `time_waiting` 超时；sleep() 执行完自动唤醒，或也可用 `wait(long timeout)` 超时后线程会自动苏醒。

线程调用对象的 wait()/notify()/notifyAll()时，都必须先获得对象的锁：

- ==> 所以只能在同步方法/同步块中被调用。

同步块比同步方法更好：同步块外的代码是异步执行的，比同步整个方法效率更高。

原则：同步的范围越小越好。

##### sleep() VS yield()

1. 优先级：sleep()不考虑线程的优先级，会给低优先级的线程运行的机会；yield()只会给相同或更高优先级的线程机会；
2. 作用：执行 sleep()后转入blocked，而执行 yield()后转入ready；
3. 异常：sleep()声明抛出 InterruptedException，而 yield()没有声明任何异常；
4. sleep() 比 yield()（跟OS CPU 调度相关）更可移植，不建议用yield()来控制并发线程。

### 创建线程

##### 创建线程的方式

1. 继承 `Thread` 类，重写 `run()`，调用 `start()` 启动线程。
   - 缺点：单继承
2. 实现 `Runnable` 接口，重写`run()`，将子类对象（作为参数）传给 Thread 类的构造器 `new Thread(Runnable obj)` 来创建线程对象，调用 `start()` 启动线程。
   - 可继承其他类，多实现；
   - void，无返回值；
   - `run()` 只能抛出运行时异常，且无法捕获处理；
   - 可用匿名内部类简化。
3. 实现 `Callable` 接口，重写 `call()`，将子类对象（作为参数）传给 Thread 类的构造器来创建线程对象，调用 `start()` 开启线程。
   - 有泛型返回值，和 `Future、FutureTask` 配合可用来获取异步执行的结果：
     - 创建 `FutureTask(Callable cal)` 对象，传给 Thread 的构造器，提交给 `ExecutorsService` 执行，放入线程池中；
   - `call()` 允许抛出异常，可获取异常信息；
4. 用（两种方式）创建**[线程池](#创建线程池)**（都实现了 ExecutorService 接口）：用时直接获取，用完放回。

##### start() VS run()

- `start()`：用于（启动线程）创建新线程，并自动执行在 `run()` 里的代码，使线程进入ready状态；只能调用一次；
  - 多次start一个线程会怎么样

- `run()`：用于执行线程的运行时代码；可重复调用；只是 Thread 的一个普通方法，仍在主线程内执行；不会创建新线程也不会调用线程的代码。

多线程执行时要用 `start()` 而不是直接调用 `run()`：

1. 调用 `start()` 方法方可启动线程并使线程进入就绪状态；
2. 直接执行 `run()` 方法，不会以多线程的方式执行；会当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行；

线程类的构造方法、静态块是被 new 此线程所在的线程所调用的，而 run 方法内的代码才是被线程自身所调用的。

##### 终止线程运行/正在运行的线程

1. `run()/call()` 执行完，线程正常结束；
2. 用 `interrupt()` 中断线程，抛出 `interruptedException`；
3. 直接调用 `stop()` 强行终止；`stop/suspend/resume` 都是过期作废的方法，容易导致死锁，故不推荐。

### 线程池

池化技术：为了减少每次获取资源的消耗，提高利用率。如线程池、数据库连接池、Http 连接池等。

##### 好处

1. 降低资源消耗。重复利用已创建的线程，减少线程创建/销毁、及系统资源的开销。
2. 提高响应速度。当任务到达时，不需等到线程创建就能立即执行。
3. 提高线程的可管理性。线程是稀缺资源，无限制的创建会消耗**系统资源**、降低系统的稳定性（OOM），可统一分配、调优和监控。

##### 实现原理

<img src="assets/图解线程池实现原理.2b9eb21a.png" alt="图解线程池实现原理" style="zoom:100%;" />

提交一个新任务到线程池时：

1. 若**核心线程池**未满/中的线程不全在执行->创建新线程执行任务；
2. 若核心线程池已满，**任务（等待）队列**未满->放入任务队列等待执行；
3. 若任务队列已满，判断线程数 < 线程池最大线程数（**线程池未满**）->创建临时线程处理任务；
4. 线程数 > 最大线程数->根据**拒绝策略**处理任务。

#### Executor 框架

<img src="assets/任务的执行相关接口.27457eb8.png" style="zoom: 60%;" /><img src="assets/Executor框架的使用示意图.36e59afa.png" style="zoom:70%;" />

##### Executor 框架结构

1. 任务：`Runnable` /`Callable ` 接口；
2. 任务的执行：任务执行机制的核心接口 `Executor` 及继承它的 `ExecutorService` 子接口（真正的线程池接口，用于创建并返回不同类型的线程池）：
   - 两个关键（线程池）实现类：`ThreadPoolExecutor` 和 `ScheduledThreadPoolExecutor`；
3. 异步计算的结果：`Future` 接口及其实现类 `FutureTask` 类；

##### 用 Executor 框架执行线程

1. 主线程首先要创建实现 `Runnable` 或 `Callable` 接口的任务对象；
2. 创建 `ExecutorService`线程池；
3. 把创建的对象交给 `ExecutorService` 线程池执行：
   1. 直接执行：`ExecutorService.execute(Runnable command)`）：没有返回值；用于提交不需返回值的任务，无法判断任务是否被线程池执行成功与否；
   2. 提交执行：`ExecutorService.submit(Runnable task/Callable <T> task)`：用于提交需要返回值的任务。和 `execute()`方法的区别是，会返回一个实现 `Future` 接口的 `FutureTask` 对象，用于判断任务是否执行成功。
      - 可通过 `Future` 的 `get()`方法来获取返回值，会阻塞当前线程直到任务完成，而使用 `get(long timeout，TimeUnit unit)`方法则会阻塞当前线程一段时间后立即返回，这时有可能任务没有执行完。
4. 由于 `FutureTask` 实现了 `Runnable`，也可创建 `FutureTask`，然后直接交给 `ExecutorService` 执行。
5. 最后，主线程可执行 `FutureTask.get()`方法来等待任务执行完成，也可执行 `FutureTask.cancel(boolean mayInterruptIfRunning)`来取消任务执行。

```
// 用构造器创建线程池
ExecutorService service = new ThreadPoolExecutor(5, 10, 10, TimeUnit.SECONDS, new LinkedBlockingQueue<>());

// 1.创建一个 Runnable 接口的（匿名）实现类，重写 run()，并提交给 execute()
service.execute(new Runnable() {
	@Override
	public void run() {
	    System.out.println("execute方式");
	}
});

// 2.创建一个 Callable 接口的（匿名）实现类，重写 call()，并提交给 submit()
Future<Integer> future = service.submit(new Callable<Integer>() {
	@Override
	public Integer call() throws Exception {
		System.out.println("submit方式");
		return 2;
	}
});

try {
	Integer number = future.get();
} catch (ExecutionException e) {
	e.printStackTrace();
}
```

#### 创建线程池

##### 一、通过构造器 ThreadPoolExecutor()

方式一：通过构造器 `ThreadPoolExecutor()` 创建；Alibaba 推荐，更明确线程池的运行规则，规避资源耗尽的风险。

<img src="assets/ThreadPoolExecutor构造方法.png" alt="ThreadPoolExecutor构造方法" style="zoom:80%;" />

四个构造器 `ThreadPoolExecutor()` 的参数有：

1. **`int corePoolSize`**：核心线程数，线程池中活跃的线程数；最小可同时运行的线程数量；
2. **`int maxinumPoolSize`**：允许同时运行的最大线程数；当队列中存放的任务达到队列容量时，可同时运行的线程数量变为最大线程数；
3. `long keepAliveTime`：空闲线程（超出核心线程数外的）的最大存活时间；
4. `TimeUnit unit`：空闲时间的单位；
5. **`BlockingQueue<runnable> workQueue`**：任务队列，存放等待执行的任务； 若当前运行的线程数量达到核心线程数，新任务会被存放在队列中。

其中前5个为共有，可选参数有：

1. `[ThreadFactory threadFactory]`：用于 executor 创建新线程；
2. `[RejectExecutionHandler handler]`：任务拒绝策略。

##### 任务拒绝策略

> 饱和策略

如果当前同时运行的线程数量达到最大线程数量且队列也已经被放满了任务时，`ThreadPoolTaskExecutor` 定义一些策略：（用 `ThreadPoolExecutor`中的枚举）

1. `.AbortPolicy`： 默认策略，抛出 `RejectedExecutionException`来拒绝新任务的处理。
2. `.CallerRunsPolicy`： 调用执行自己的线程运行任务，即直接在调用`execute`方法的线程中运行(`run`) 被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。
   - 会降低对于新任务提交速度，影响程序的整体性能。用于可承受此延迟、且要求任何一个任务请求都要被执行的情况。
3. `.DiscardPolicy`： 不处理新任务，直接丢弃掉。
4. `.DiscardOldestPolicy`： 此策略将丢弃最早的未处理的任务请求。

##### 二、通过 Executor 框架的 Executors 工具类 

方式二： 通过 `Executor` 框架的工具类/线程池的静态工厂类 `Executors` 来实现。目的是将任务提交和运行分离，用户不需从代码层考虑设计任务的提交运行。**不推荐**。

<img src="assets/Executor框架的工具类.png" alt="Executor框架的工具类" style="zoom: 80%;" />

常见线程池及创建接口（应用场景）：

1. `newSingleThreadExecutor()`：创建只有一个线程的线程池。若多个任务被提交到线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
2. `newFixedThreadPool(n)`：创建（可重用）固定线程数的线程池；不推荐。线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行；若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时再处理。
3. `newCachedThreadPool()`：创建可按需创建新线程的线程池。线程池的线程数量不确定，但若有空闲线程可复用，则会优先使用可复用的线程；若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。
4. `newScheduledThreadPool(corePoolSize)`：创建可定时执行的线程池，指定核心线程数。

5. `newWorkStealingPool()`：创建有多个任务队列的线程池。

注意：

- 1、2：允许的请求队列长度为 `Integer.MAX_VALUE`，可能会堆积大量的请求，从而导致 OOM；
- 3、4：允许的创建线程数量为 `Integer.MAX_VALUE`，可能会创建大量的线程，从而导致 OOM；

#### 线程池大小确定

线程池中的线程数量

- 太小，（如果同一时间有大量任务/请求需处理，）可能会导致大量的请求/任务堆积在任务队列中（排队）等待执行，甚至会出现任务队列满导致 OOM；CPU 没有得到充分利用。

- 太大，可能会同时争取 CPU 资源，导致频繁的上下文切换，增加线程的执行时间，影响整体执行效率。

有一个简单且适用面较广的公式（N 为 CPU 核心数）：

1. CPU 密集型任务（N+1）： 利用 CPU 计算能力的任务，消耗的主要是 CPU 资源，如在内存中对大量数据进行排序；
   - 线程偶发的缺页中断，或其它原因一旦导致任务暂停，CPU 就会处于空闲状态，（比 CPU 核心数）多出来的一个线程就可充分利用 CPU 的空闲时间。
2. I/O 密集型任务（2N）： 特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上。如，但凡涉及到网络读取，文件读取这类。
   - 系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU，这时就可将 CPU 交出给其它线程使用，可多配置一些线程。

### 线程同步机制

##### 同步 VS 异步

同步：必须等被调用的方法结束后，后面的代码才能执行。发出一个调用后，在没有得到结果前， 该调用就不可返回，一直等待。

异步：不管被调用方法是否完成，都会继续执行后面的代码，调用完成后会通知调用者。调用在发出后，不用等待返回结果，该调用直接返回。

- 异步代码题，说出打印顺序

##### 线程间的同步方式

线程同步：两个或多个共享关键资源的线程并发执行。用于避免关键资源使用冲突。

1. synchronized
2. 同步工具类：
   1. 阻塞队列
   2. 闭锁
3. [常用的 AQS 组件/同步器](#常用的 AQS 组件/同步器)
   1. 信号量（Semphares)）
   2. 栅栏/屏障（barrier）
   3. FutureTask；
4. 互斥量（Mutex）：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。如 synchronized 关键词和各种 Lock（互斥锁、读写锁、记录锁、自旋锁）。
5. 事件（Event)）：Wait/Notify：通过通知的方式来保持多线程同步，方便比较多线程优先级。
6. 条件变量

##### synchronized

用来控制线程同步：可保证在任意时刻只有一个线程执行方法/代码段

- 作用范围是 synchronized 后大括号{}中的代码
- 作用对象是调用{}的对象；

用法：

1. 修饰实例方法（同步方法）：作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁。

2. 修饰静态方法：因其是类成员，相当于给当前类加锁，作用于类的所有对象实例，访问静态 synchronized 方法、进入同步代码前要获得当前类的锁，而访问非静态 synchronized 方法占用的是当前实例对象锁，二者不互斥。

3. 修饰代码块（同步语句块）：synchronized(this|object) 表示进入同步代码库前要获得给定对象的锁。

4. 不能修饰构造器：其本身就是线程安全的，不存在同步的构造方法一说。

##### 生产者消费者模型

作用：

1. 通过平衡生产者的生产能力和消费者的消费能力来提升整个系统的运行效率；
2. 解耦；

实现

- wait 和 notify
- ReentrantLock
- BlockQueue
- Semaphore
- PipedInputStream

### JMM（Java 内存模型）

并发编程下，像 CPU 多级缓存和指令重排这类设计可能会导致（多线程）程序运行出现一些问题。为此，JMM 抽象了 happens-before 原则来解决指令重排问题。

##### 指令重排序

> 简单来说就是系统在执行代码时并不一定是按照代码顺序依次执行。

为了提升执行速度/性能，计算机在执行程序代码的时候，会对指令进行重排序。

常见的指令重排序有下面 2 种情况：

- 编译器优化重排：编译器（包括 JVM、JIT 编译器等）在不改变单线程程序语义的前提下，重新安排语句的执行顺序。
- 指令并行重排：现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可改变语句对应机器指令的执行顺序。指令重排序可保证串行语义一致，但不保证多线程间的语义也一致 ，可能会导致一些问题。
- 内存系统也会有“重排序”，但不是真正意义上的。在 JMM 里表现为主存和本地内存的内容可能不一致，进而导致程序在多线程下执行可能出现问题。

##### CPU 缓存模型和 JMM 抽象示意图

<img src="assets/cpu-cache-protocol.b83e957c.jpg" alt="缓存一致性协议" style="zoom:55%;" /><img src="assets/jmm.png" alt="JMM(Java 内存模型)" style="zoom: 70%;" />

CPU 缓存模型：

1. Main Memory（主内存）：物理内存，虚拟机内存的一部分，内存缓存的是硬盘数据，用于解决硬盘访问速度过慢的问题；
2. CPU Cache（CPU 缓存）：为了解决 CPU 处理速度和内存处理速度不对等的问题，通常分为三层，`L1,L2,L3 Cache`；
3. 工作方式： 先从主内存复制一份数据到 CPU Cache 中，CPU 可直接从 CPU Cache 中读写数据；当运算（操作）完成后，通过**缓存一致性协议**将（运算得到的）数据写回主内存。

JMM（Java内存模型）抽象了线程和主内存间的关系，抽象示意图：

1. 主内存：线程间的**共享变量**（所有线程创建的实例对象）都存放在主内存中，不管该实例对象是成员变量还是方法中的本地变量（也称局部变量）；
2. 本地内存 ：每个线程都有一个私有的本地内存（工作内存），存储（主内存中）共享变量的副本，无法访问其他线程的本地内存；对变量的所有操作都必须在工作内存进行，不能直接读写主内存数据。

线程间主要通过读-写共享变量来完成隐式通信。

线程 1 与线程 2 间进行通信的 2 个步骤：

1. 线程 1 把本地内存中修改过的共享变量副本的值同步到主内存中；
2. 线程 2 到主存中读取对应的共享变量的值。

也就是说，JMM 为共享变量提供了可见性的保障。

Java 内存区域和 JMM 的区别：

- Java 内存区域：和 JVM 的内存分配机制、运行时数据区相关，定义了 JVM 在运行时如何分区存储程序数据。
-  JMM：和 Java 的并发编程相关，抽象了线程和主内存之间的关系；规定了从 Java 源代码到 CPU 可执行指令的转化过程要遵守哪些（和并发相关的）原则和规范，主要目的是为了简化多线程编程，增强程序可移植性。

##### happens-before 规则

<img src="assets/image-20220731155332375.png" alt="img" style="zoom: 67%;" />

先行发生原则：定义了操作 A 必然先行发生于 B 的一些规则。

- 符合规则，不需额外做同步措施；
- 不符合规则，一定是非线程安全的。

happens-before 八大原则：

1. **程序顺序规则**：一个线程内，按照代码顺序，写在前面的操作 happens-before（先行发生）于后面的；
2. **锁定规则**：对同一个锁的，unlock 操作 happens-before 于 lock 操作；
3. **volatile 变量规则**：对同一 volatile 变量的，写操作 happens-before 于读操作；
4. **传递性规则**：如果操作 A 先行发生于B，B 先行发生于C，则 A  happens-before 于 C；
5. **线程启动规则**：线程的 start() happens-before 于此线程的每个动作；
6. 线程中断规则：对线程 interrupt() 的调用 happens-before 于被中断线程的代码检测到中断事件的发生；
7. 线程终止规则：线程中所有操作 happens-before 于对线程的终止检测；
8. 对象终结规则：对象的初始化 happens-before 于 finalize() 方法；

as-if-serial VS happens-before 规则：

as-if-serial：编译器等会对原始程序进行指令重排序和优化，但和原结果一致。

1. 语义：保证单线程和正确同步的多线程 程序的执行结果不变。
2. 对程序员：分别按程序的顺序和happens-before指定的顺序执行。
3. 目的：都是为（在不改变程序执行结果的前提下，）尽可能提高执行的并行度。

##### volatile

volatile 修饰共享变量：保证每个线程都能获取主存中的最新值，避免出现数据脏读。

1. 保证变量对所有线程的可见性：一个线程修改了变量值，立即更新到主存，对其他线程立即可见。其他线程直接从主存读取新值，而不是工作内存中的副本；
2. 禁止指令重排，保证有序性；
3. 不能单独保证原子性，结合 CAS 可保证。

为了提高性能，处理器和编译器常会对指令重排序：
- 不影响单线程环境的执行结果，但会破坏多线程的执行语义；
- 存在数据依赖关系的不允许重排序。

##### volatile VS synchronized

1. 修饰：volatile 只能用于变量而 synchronized 可修饰类、方法、变量及代码块；
2. 作用：volatile 用于解决变量在多个线程间的可见性（线程通信）； synchronized 用于解决多个线程间访问资源的同步性（线程同步）。
3. 性质：volatile 能保证数据的可见性（和有序性），但不能保证原子性；synchronized 两者都能保证。
4. 性能：volatile 是线程同步的轻量级实现，性能比 synchronized 好；
5. 阻塞：volatile 不会造成线程阻塞；synchronized 可能造成 。
6. 优化：volatile 变量不会被编译器优化；synchronized变量可被优化。

##### ThreadLocal

`ThreadLocal`（线程共享变量）：为每个线程维护一个本地 Map，key 为 ThreadLocal 对象，value 为对应线程的变量副本（Entry 对象）==>用于查找；以空间换时间。

用途：
1. （主要）用于线程间的数据隔离，解决线程安全问题；填充的数据只属于当前线程；
2. 对象跨层传递时可避免多次传递，打破层次约束；
3. 进行事务操作，用于存储线程事物信息；
4. 数据库连接，Session会话管理。

![img](assets/5.deed12c8.png)

内存泄漏：由于 ThreadLocal 是弱引用，Entry 的 value 是强引用，因此当 ThreadLocal 被回收后，value 依旧不会被释放，产生内存泄漏。

避免：
- 用完 ThreadLocal 后调用 remove() 手动清空；必须回收自定义的 ThreadLocal 变量记录的当前线程的值，尤其在线程池场景下，线程经常会被复用。尽量用 try-finally 块进行回收。
- 用 `private static ThreadLocal` 修饰变量，任何时候都能访问 value，进而清除掉。是针对一个线程内所有操作共享的，故设置为 static，所有此类实例共享此静态变量。即，类第一次被使用时装载，只分配一块存储空间，所有（本线程内定义的）此类的对象都可操控这个变量。

### 线程安全

定义：多线程下（重复）运行的结果与单线程的结果始终一致，且其他变量的值也和预期的值始终一致。

堆是所有线程共享，栈是线程安全的。

##### 线程安全级别

1. 不可变（Immutable）：
   - 对象一旦被创建，任何一个线程都改变不了它的状态（数据/属性值），除非新创建一个；
   - 所有域都是 final 类型，且被正确创建（创建期间没有 this 引用的溢出）
     ==>（保证了对象的内存可见性，）不需任何同步手段就可直接在多线程下使用。

如 String、包装类、BigInteger 和 BigDecimal 等。

2. 绝对线程安全：不管运行时环境如何，调用者都不需额外的同步措施。如
   - `CopyOnWriteArrayList`
   - `CopyOnWriteArraySet`
3. 相对线程安全，即通常所说的线程安全：如Vector的add()、remove()都是原子操作，但如果多个线程同时执行遍历和add() ，会出现ConcurrentModificationException（即fail-fast机制）。

4. 线程非安全：ArrayList、LinkedList、HashMap等。

##### 线程安全工具

1. 同步容器：`Collections.synchorizedXXX`；
2. [同步工具类](#线程间的同步方式)：阻塞队列、闭锁、信号量、栅栏、FutureTask；
3. 并发容器类：`CopyOnWriteArrayList`、`ConcurrentLinkedQueue`、`BlockingQueue`、`ConcurrentHashMap`、`ConcurrentSkipListMap` ，见 Java 集合框架；

##### 线程安全策略/三要素

保证三要素、即保证线程安全：

1. 原子性（Atomicity）：一个（或多个操作）是不可中断的，要么全都执行，要么全都不执行。实现方式：
     1. Lock（手动）锁：保证同时只有一个线程能拿到锁，并执行申请锁和释放锁间的代码；
     2. synchronized 同步方法/代码块：对线程加独占锁，修饰的类/方法/变量/代码片段同一时间只允许一个线程访问；
     3. 用安全类，如 Atomic 原子类（CAS）、Unsafe 类；如 i++ 是非线程安全的，可用`AtomicInteger.incrementAndGet()`替换；

2. 可见性（Visibility）：一个线程修改共享变量后，其他线程能立即看到最新值。
    1. volatile：指示 JVM 这个变量是共享且不稳定的；保证每次使用共享变量前都从主内存重新读取，修改后的新值立即同步到主内存；
    2. Lock；
    3. synchronized：在释放锁前将工作内存新值更新到主存中；

3. 有序性（Ordering）：对于改变顺序不影响语义的代码，JVM和CPU编译时可能会优化代码和指令重排；保证线程内串行语义？虽然多线程存在并发和指令优化等操作，但在本线程内观察所有执行操作是有序的。
    1. volatile：有禁止[指令重排序](#指令重排徐)的语义；
    2. synchronized：变量在同一个时刻只允许一个线程对其进行 lock 操作，使有同一个锁的两同步块只能串行地进入；
    3. [Happens-Before 规则](#happens-before 规则)：两个操作的执行顺序只要可通过 happens-before 推导出来，则 JVM 会保证其顺序性，否则可任意重排序以提高效率。

##### 死锁

> 见操作系统

##### 悲观锁 VS 乐观锁

悲观锁：每次获取数据时，都担心数据被修改，因此加独占锁，确保自己使用的过程中数据不会被别人修改，使用完成后解锁；期间对该数据读写的其他线程都会等待/阻塞；synchronized 的实现，传统的关系型数据库如行锁，表锁等，读锁，写锁等。遵循一锁二判三更新四释放的原则。

使用场景：写多读少，并发量不大
- 乐观锁在获得锁的同时已完成了更新，校验逻辑易出现漏洞，另外，对冲突的解决策略有较复杂的要求，处理不当易造成系统压力或数据异常，所以资金相关的金融敏感信息不建议使用乐观锁更新。

缺点：导致频繁的上下文切换和调度延时，降低性能；一个线程持有锁会导致其他所有需要此锁的线程挂起。

乐观锁：对于并发间操作产生的线程安全问题持乐观状态，认为竞争不总是会发生，不需持有锁；每次获取数据时，都不担心数据被修改，因此读操作前不加锁，写操作时才判断数据在此期间是否被其他线程修改。如果发生修改，则返回写入失败；如果没有被修改，则执行修改操作，返回修改成功。

期间该数据可被其他线程读写；

使用场景：读多写少

一般用CAS算法实现。

在项目开发中的实践：SVN、Git等版本控制管理器，提交时对比版本号，如果远程仓库的版本号和本地的不一样表示有人已提交过代码，需要先更新到本地处理一下版本冲突问题。

##### CAS，Compare and Swap，比较-交换

原理：基于乐观锁，当且仅当预期原值 A 和内存位置 V 的值相同时，才将 V 修改为新值 B 并返回true，否则处理器什么都不做。解决多线程并行情况下使用锁造成性能损耗的一种机制，这是硬件实现的原子操作。

产生的问题：

1. **ABA 问题**：线程1准备将内存值由A改为C
 1. 线程1从内存位置 V读取了数据A；
    2. 由于没有锁，线程2将内存位置 V 的值由A改为B，又由B改回A；
    3. 线程1通过CAS比较，发现数据仍是A没变，很容易认为在此期间没有线程修改过数据，就写成了C，返回成功；
    4. 如果C的值在ABA的线程中发生改变，则不能实现预期结果。
    5. JUC包中 AtomicStampedReference 类（加入版本号，对比内存值+版本号）解决 ABA 问题。

2. 循环时间长开销大：并发量较高，资源竞争严重时，许多线程反复尝试更新某一个变量，CAS操作却又一直不成功（自旋），相当于死循环，浪费CPU 资源。

3. 只能保证一个共享变量的原子操作：对多个共享变量无法保证。
    - 此时可用synchronized锁；可用AtomicReference来保证对象间的原子性，把多个对象放入CAS中。

### JUC 并发工具类

##### Unsafe 类

使 Java 拥有（类似 C 语言指针一样）操作内存空间的能力，是 Java 并发开发的基础。

主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等。方法的实现需依赖本地方法（Native Method）。

#### Atomic 原子类

原子类：有原子操作特征的类，指一个操作是不可中断的。在多线程一起执行时，一个操作一旦开始，就不会被其他线程干扰。存放在 `java.util.concurrent.atomic`下。

##### 四类原子类

1. 基本类型：
   1. `AtomicInteger`：整型原子类
   2. `AtomicLong`：长整型原子类
   3. `AtomicBoolean`：布尔型原子类
2. 数组类型：
   1. `AtomicIntegerArray`：整型数组原子类
   2. `AtomicLongArray`：长整型数组原子类
   3. `AtomicReferenceArray`：引用类型数组原子类
3. 引用类型：
   1. `AtomicReference`：引用类型原子类
   2. `AtomicStampedReference`：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可解决用 CAS 进行原子更新时可能出现的 ABA 问题。 
   3. `AtomicMarkableReference` ：原子更新带有标记位的引用类型
4. 对象的属性修改类型：
   1. `AtomicIntegerFieldUpdater`：原子更新整型字段的更新器
   2. `AtomicLongFieldUpdater`：原子更新长整型字段的更新器
   3. `AtomicReferenceFieldUpdater`：原子更新引用类型字段的更新器

##### Atomic 类实现原理

原理：用 `CAS 机制  + volatile` 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，提升执行效率。

如 AtomicIntger 的实现原理：`getAndIncrement()` 方法：以原子方式将当前的值加1。

##### AtomicInteger 类常用方法

```
public final int get() // 获取当前的值
public final int getAndSet(int newValue) // 获取当前的值，并设置新的值
public final int getAndIncrement() // 获取当前的值，并自增
public final int getAndDecrement() // 获取当前的值，并自减
public final int getAndAdd(int delta) // 获取当前的值，并加上预期的值
boolean compareAndSet(int expect, int update) // 如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）
public final void lazySet(int newValue) // 最终设置为newValue,使用 lazySet 设置后可能导致其他线程在之后的一小段时间内还是可读到旧值。
```

`AtomicInteger` 类的使用示例：

使用 `AtomicInteger` 之后，不用对 `increment()` 方法加锁也可保证线程安全。

```
class AtomicIntegerTest {
    private AtomicInteger count = new AtomicInteger();
    // 使用AtomicInteger之后，不需对该方法加锁，也可实现线程安全。
    public void increment() {
        count.incrementAndGet();
    }
    public int getCount() {
        return count.get();
    }
}
```

#### JUC 核心类 AQS

`AbstractQueuedSynchronizer(AQS)` 抽象队列同步器：在 `java.util.concurrent.locks` 包下，是（利用先进先出 CLH 队列锁实现的）底层抽象同步工具类；

- 用来构建锁和同步器的框架，（通过继承 `AQS `类并重写其模版方法）能简单高效地构造出大量应用广泛的同步器。如： [常用的 AQS 组件/同步器](#常用的 AQS 组件/同步器)。

##### AQS 原理

<img src="assets/AQS原理图.png" alt="AQS原理图" style="zoom: 67%;" />

AQS 核心思想是：

1. AQS 用一个 `volatile int state` 变量作为共享资源：
   1. `volatile` 能保证多线程下的可见性；
   2. `state=1` 代表当前对象锁已被占有；
   3. state 状态信息通过 protected 类型的 `getState，setState，compareAndSetState(CAS )` 进行操作来保证其并发修改的安全性；
2. 如果被请求的共享资源空闲，获取成功执行临界区代码，则将当前请求资源的线程 1 设置为有效的工作线程，并将共享资源设置为锁定状态，释放资源时会通知/唤醒同步队列中的等待线程；
3. 如果被请求的共享资源被占用，多线程争用资源被阻塞时，线程获取资源/锁失败，会进入 FIFO 等待（同步）队列挂起；AQS 作为线程阻塞等待及被唤醒时锁分配的机制。

##### AQS的两种资源共享方式

> 两种功能共享方式

1. `Exclusive`（独占锁）：每次只能有一个线程持有锁，能执行，如 `ReentrantLock` 提供了两种锁获取方式：
    - 公平锁：按线程在队列中（发出请求）的排队顺序获得锁，先到先得；
    - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁（发出请求后立即尝试获取锁），谁抢到就是谁的，获取失败才排队等待。

2. `Share`（共享锁）：多个线程可同时获取锁同时执行，并发访问共享资源，如 `Semaphore、CountDownLatch、CyclicBarrier、ReadWriteLock`。

##### 常用的 AQS 组件/同步器

1. `Semaphore`（信号量）：限制某段代码块的并发数，允许同一时刻多个线程同时访问同一资源，但需控制最大线程数量。
   - `synchronized/ReentrantLock`（相当于构造器参数最大并发数/计数器n=1）都是一次只允许一个线程访问某个资源。
2. `CountDownLatch`（倒计时器）：是一个同步工具类，用来协调多个线程间的同步。用来控制当前线程等待直到倒计时结束（其它线程都执行完毕），再开始执行。
   - 通过计数器实现，初始值是线程数量，每执行完一个线程-1。只能一次性使用。
3. `CyclicBarrier`（循环栅栏）：和 CountDownLatch 类似，但可重复使用（reset）。让一组线程到达一个屏障（同步点）时被阻塞，直到最后一个线程到达屏障（所有线程的任务都执行完毕）时，才开门，所有被屏障拦截的线程才会继续干活。
   - 如：用多线程读取多个文件处理的场景。
4. **`ReentrantLock`（可重入锁）**：能对共享/临界资源重复加锁，即当前线程再次获取该锁不会阻塞。基于AQS，唯一实现了Lock接口的类。
5. `ReentrantReadWriteLock`（读-写锁）：可看作组合式，允许一个资源可被多个读/写操作访问，但读-写不能同时进行。允许多个线程同时对某一资源进行读。
6. `SynchronousQueue`（同步队列）
7. `FutureTask`
