---
title: 数据库
categories:
  - 计算机基础
tags:
location:
abbrlink: '7fws438h'
permalink: '7fws438h'
date: 2022-03-01 13:42:12
updated: 2022-03-01 13:42:12
---

> 摘要：计算机基础之数据库，包括SQL语句书写，数据类型，索引/锁，MySQL等。

<!-- more -->

## 数据库入门

- DBMS：数据库管理系统

### 分类

- 关系型数据库：建立在关系模型的基础上，借助于集合代数等数学概念和方法处理数据。由多张能互相连接的表组成。主要用于执行规模小而读写频繁，或大批量极少写~~访问~~的事务。
  1. 商用数据库，如：Oracle，SQL Server，DB2 等；
  2. 开源数据库，如：
    1. **MySQL Community Server** (GPL) 社区版：主要用于业务数据存储；
    2. MariaDB 分支：开源社区用来规避 MySQL 闭源的风险，大部分跟 MySQL 5.5 以前的版本使用差不多；
    3. PostgreSQL 等；
  3. 桌面数据库，如：微软 Access，适合桌面应用程序使用；
  4. 嵌入式数据库，如：Sqlite，适合手机应用和桌面程序。
- NoSQL 非关系型数据库：关系数据库在一些数据敏感的应用中读写性能较差，如为海量文档创建索引、高流量网站的网页服务，及发送流式媒体，故采用 **NoSQL**；优点：高效读写海量数据，支持高并发；可是 key-value、文档、图片等形式，可用硬盘或随机存储器作为载体，不支持SQL；包括：
  1. **Redis**：Key-value；RAM 存储；缓存数据存储；
  2. MongoDB：Nodejs 在 Mongoose 包的帮助下 JSON 的数据格式直接插入；用户行为分析数据存储；
  3. ElasticSearch：搜索数据存储；
  4. Apache Cassandra（Facebook 使用、高度可扩展）、Dynamo；
  5. MemcacheDB 和 HBase 等。

### 数据模型

数据库按照数据结构来组织、存储和管理数据，共有三种模型：

1. 层次模型：轻量级数据访问协议，如树；
2. 网状模型：大型数据储存；
3. 关系模型：表明数据库中存储数据间一对一、一对多、多对多的联系，如表格。

### 主键

- 元组：表中的一行/一条记录；
- 码：数据表中关系的某个或某几个属性的组合，用于区分每条记录；
  - 候选码：能唯一标识一条记录的最小属性（列）集和；可被选为主码的属性或属性组；
- 主属性：候选码属性的并集；
  - 非主属性：相对于主属性来说，不包含在候选码中的属性。
- 主键 `id`：用于唯一标识一条记录的某个属性，不可重复、不可空，一个表只能有一个主键。unique + not null；基本原则：选取完全业务无关的字段，不可用身份证号、手机号、邮箱地址等（看上去唯一但可能会更改）。可用作 `id` 字段的类型有：
  - 自增整数类型：INT 上限约21亿，BIGINT约922亿亿。
  - 全局唯一GUID字符串类型：GUID算法通过网卡MAC地址、时间戳和随机数保证任意计算机在任意时间生成的字符串都是不同的。
- 外键：用来和其他表建立联系，是另一表的主键，可重复、可为空。一个表可有多个外键。当表越来越多，关系越来越复杂时，一般在设计数据库时通过外键来标注表与表间的关系；但在数据库中往往不使用外键，而是通过逻辑来关联。

**不用外键与级联更新**，一切外键概念必须在应用层解决：

如：学生表中的 student_id 是主键，那么成绩表中的 student_id 则为外键。如果更新学生表中的 student_id，同时触发成绩表中的 student_id 更新，即为**级联更新**。

1. 适用于单机低并发，不适合分布式、高并发集群；对分库分表不友好，分库分表下外键无法生效；
2. 级联更新是强阻塞，存在数据库更新风暴的风险；
3. 外键影响数据库的插入速度；增加了复杂性： 每次做DELETE 或UPDATE都必须考虑外键约束，需额外维护；

### 数据库范式

##### 函数依赖

1. **函数依赖** ：若在一张表中，在属性（或属性组）X 的值确定的情况下，必定能确定属性 Y 的值，那么就可说 Y 函数依赖于 X，写作 X → Y。
2. **部分函数依赖** ：如果 X→Y，且存在 X 的一个真子集 X0（部分关键字），使得 X0→Y，则称 Y 对 X 部分函数依赖。如学生基本信息表 R关系（学号，身份证号，姓名）中，（学号，身份证号）->（姓名），（学号）->（姓名），（身份证号）->（姓名）；姓名部分函数依赖于（学号，身份证号）；
3. **完全函数依赖**：在一个关系中，某个非主属性数据项依赖于**全部关键字**。不同班级学生编号可能相同，在 R 关系中，（班级，学生编号）->（姓名），但（学生编号）->（姓名）不成立，（班级）->（姓名）不成立，姓名完全函数依赖于（班级，学生编号）；
4. **传递函数依赖** ： 某个字段依赖于主键，而有其他字段依赖于该字段。会导致数据冗余和异常。如，在关系 R（学号 , 姓名, 系名，系主任）中，学号 → 系名，系名 → 系主任，非主属性系主任对于学号有传递函数依赖。

##### 范式

用于规范建表，划分字段。

1. `1NF`（第一范式）：对属性的原子性约束，要求属性（表中的字段）不可再分（为其他字段）。是所有关系型数据库的最基本要求，即创建的表一定满足第一范式。
2. `2NF`（第二范式）：对记录的惟一性约束，要求主键可以唯一标识记录。在 `1NF` 基础上，消除了非主属性对于**码**的**部分函数依赖**，非主属性都依赖于**主键**。
3. `3NF`（第三范式）：对字段冗余性的约束，要求字段没有冗余，即任何字段不能由其他字段派生出来。在 `2NF` 基础上，消除了非主属性对于**码**的**传递函数依赖**（任何非主属性不依赖于其它非主属性）。基本上解决了数据冗余，插入异常，修改异常，删除异常的问题。
4. `BCNF`：主属性内部不能有**部分或传递依赖**。

### 数据库设计

> 数据库设计就是建立数据存储模型。

##### 设计步骤

1. 需求分析 : 包括数据、功能和性能需求。根据功能模块划分实体（往往指现实世界中一个完整单位），实体间的关系，各实体的属性、可选唯一标识属性（主键）、数据存储特点/生命周期（是否常用，分库分表，永久存储，定期归档，定期清空等）。
2. 概要设计 : 主要用 E-R 模型进行设计，如用 Visio 画 `E-R` 图。
3. 逻辑设计/详细设计 : 通过将 E-R 图转换成表，实现从 E-R 模型到关系模型的转换，并应用三大范式优化。
4. 物理结构设计 : 为设计的数据库选择合适的存储结构和存取路径，做具体的技术选型。
5. 数据库实现 : 包括 SQL 编程（创建数据库表）、测试和试运行
6. 数据库的运行和维护 : log 日志，根据l新需求进行建表、索引优化、大表拆分。

##### E-R 图

E-R 图/实体-联系图：表示实体类型、属性和联系。

- 实体：矩形；

- 属性： <u>唯一标识属性（主键）</u>、派生属性、可选属性、联系属性；

- 关系：1:1，1:N，M：N；

- 元组、候选码、主码、域；

- 多值属性：

E-R 图中的冲突有三种：属性冲突、命名冲突、结构冲突。

<img src="assets/E-R图示例.png" style="zoom: 67%;" />

数据库实际的关系模型：

<img src="assets/数据库实际的关系模型.png" alt="关系模型" style="zoom: 80%;" />

UML 类图

> 见设计模式。

## MySQL

是一种关系型数据库：用于持久化存储系统中的数据，建立在关系模型的基础上。

### 优势

1. **开源**。
2. 用 C 和 C++ 编写，并用了多种编译器进行测试，保证源代码的**可移植性**。
3. **跨平台**：支持 Windows、Linux、Mac OS、Solaris 等操作系统。SQL Server 只支持 Windows。
4. 为多种**编程语言**提供了API，包括 C、C++、C#、Java、PHP、Python、Ruby 等。
5. 支持**多语言编码**，如中文的 GB 2312、BIG5、日文的 Shift JIS 等都可用作数据表名和列名。
6. 支持**多线程**，充分利用 CPU资源，支持多用户。
7. 基于 C/S 模式的 DBMS。既能作为单独的应用程序在 C/S 网络环境中运行，也能作为程序库嵌入其他软件。
   - 另一类是基于共享文件系统的 DBMS，如 Microsoft Access 和 FileMaker，主要用于桌面用途，不适合高端或更关键的应用。
8. 提供 TCP/IP、ODBC 和 JDBC 等多种**数据库连接**途径。
9. 提供用于管理、检查、优化**数据库操作的管理工具**。
  1. MyCli，默认；
  2. Navicat、MySQL Workbench 图形客户端；
  3. phpMyAdmin；
10. 优化的**SQL**查询算法，有效地提高查询速度。
11. 可处理拥有上千万条记录的大型数据库。

### 安装

##### 版本号

MySQL 的命名机制由 3 个数字和 1 个后缀组成，如 `mysql-5.7.20`：

> 源自Github 上面的[语义化版本标准](http://semver.org/lang/zh-CN/) 

1. 第 1 个数字`5`是主版本号：用于描述文件的格式，所有版本 5 的发行版都有相同的文件夹格式。表示做了不兼容的 API 修改。
2. 第 2 个数字`7`是发行级别：表示做了向下兼容的功能性新增；+ 主版本号组合 = 发行序列号，描述了稳定的特征集。
3. 第 3 个数字`20`是在此发行系列的版本号：随每次新发行的版本递增。表示做了向下兼容的问题修正。通常选择已发行的最新版本。

##### 使用

- MySQL Client 的可执行程序是 mysql，在其中输入的 SQL 语句通过**TCP连接**发送到 MySQL Server；

- MySQL Server 的可执行程序是 mysqld，本机默认IP地址为 `127.0.0.1:3306`，可用远程IP。

```
mysql -h 127.0.0.1:3306 -u root -p
mysqld start/stop/restatr/status
```

### 字符集

数据库和表的字符集统一用 UTF8，兼容性更好。

```
CHARACTER SET UTF8
```

乱码的本质： 编码和解码时用了不同或不兼容的字符集 。

1. `ASCII`： 128 个字符，ASCII 扩展字符集256个。
2. `GB2312`：对于英语字符，和 ASCII 码是相同的，`1` 字节编码即可；对于非英字符，需 2 字节编码。涵盖了绝大部分常用汉字，不支持绝大部分的生僻字和繁体字。
  - `GBK`：兼容并扩展 `GB2312` 字符集。
3. `Unicode` 字符集：包含了世界上几乎所有已知字符。
  - `UTF-8`：用 `1-4 `个字节为每个字符编码，对于英语字符，和 ASCII 码相同。是目前使用最广的字符编码。

MySQL 字符集中有两套 UTF-8 编码实现：

- **`utf8`** ： 只支持`1-3`个字节 。中文占 3 个字节，其他数字、英文、符号占一个字节。
- **`utf8mb4`** ： UTF-8 的完整实现，最多支持用 `4` 个字节表示字符；用来存储 `emoji` 符号、一些较复杂的文字、繁体字，这些占 `4` 个字节。

```
SELECT LENGTH("轻松工作"); -- 返回为 12
SELECT CHARACTER_LENGTH("轻松工作"); -- 返回为 4
```

### 数据类型和函数

> 大于显示宽度也可插入

##### 数据类型

1. 数值类型：可用 UNSIGNED 修饰
   1. 整型
      - `tinyint unsigned`（1 Byte）：0 ~ 255，可表示 Bool
      - `smallint`（2 Byte）：0 ~ 65535
      - `mediumint`（3 Byte）：0 ~ 1677w
      - `int`（4 Byte）/`int(M位数)`：0 ~ 42亿
      - `bigint`（8 Byte）：必须对应类属性的 `Long` 类型，否则可能会 Integer 溢出。
   2. 浮点型：可用`(精度M, 标度D)`，分别表示（总位数/显示宽度，小数位数）。注意浮点数相减和比较运算时易出问题。
      - `real`（4 Byte）/`float(M, D小数位数)`：比较粗略但开销相对较少；一般选择；
      - `double(M, D)`（8 Byte）
   3. 定点数
      - `decimal(M, D)`：优点是不存在舍入误差，值和计算都是精确的。不同于浮点数的四舍五入，实际上是以字符串的形式存放；用于对精度要求比较高时，如金额、货币、科学数据；占用空间由定义的宽度决定，每 4 个字节可存储 9 位数字，且小数点占用一个字节。
2. 日期时间类型

   - `year`：YYYY
   - `date`：YYYY-MM-DD
   - `datetime`（8Byte）：YYYY-MM-DD HH:MM:SS，create_time
   - `time`：HH:MM:SS
   - `timestamp`（4Byte）：YYYY-MM-DD HH:MM:SS，1970-01-01 00:00:01 ~ 2038-01-19-03:14:07，超出取值范围的用 `DATETIME`；
     - `INSERT INTO time_zone_test(date_time, time_stamp) VALUES(NOW(), NOW());`用于需记录时区的 create_time。
3. 字符串类型
   - `char(N)`：固定长度，不管存入的数据多长，均占 N 字节；会自动删除插入数据的尾部空格；处理速度快，浪费空间；
   - `varchar(M)`：M 为0～65535；可变长度，所占的字节数为实际长度 L+1。对应 String。
   - `tinytext(255), text(65535，64k), mediumtext, longtext(4GB)`
   - `blob`：避免使用
   - `binary, varbinary`

   - `enum(‘v1’, ...)`：最多 65535 个元素；从多个值中取一个时用 ENUM；避免使用；
   - `set(‘v1’, ...)`：最多 64 个成员；取多个值时用SET；

```
CREATE TABLE tab ( gender SET('man', 'woman', 'no') );
INSERT INTO tab VALUES ('man', 'man');
```

##### 字段类型选择原则

1. 数据： int > datetime > char > varchar。
   - unsigned bigint id
2. 用 int 来存储时间只能存到 2038-1-19 11：14：07，需转换，访存频繁用 datetime。
4. 电话号码、信用卡号和社会保险号含非数字字符空格和短划线，不能存为数值类型，以避免丢失开头的“零”。
4. 一般 `<` 50个字节时用 char （除了个别很少用到的字段，也可用 varchar 来节省空间）。
5. 存储引擎对于选择 CHAR 和 VARCHAR 的影响:
   - 对于 MyISAM ，最好用固定长度的数据列。可使整个表静态化，从而使数据检索更快，用空间换时间。
   - 对于 InnoDB，最好用可变长度的数据列，InnoDB 数据表的存储格式不分固定长度和可变长度，因此用 CHAR 不一定比用 VARCHAR 更好，但由于 VARCHAR 是按照实际的长度存储，比较节省空间，对磁盘 I/O 和数据存储总量比较好。

##### 函数

[MySQL常用函数汇总](http://c.biancheng.net/mysql/function/)

- 数学函数
- 字符串函数
- 日期和时间函数
- 聚合函数：MAX、MIN、COUNT、SUM、AVG；
- 条件判断函数：IF 、IFNULL、CASE 和 WHERE 语句等；
- 系统信息函数：用于获取 MySQL 数据库的系统信息，包括获取数据库名、获取当前用户和获取数据库版本的函数等；
- 加密函数、格式化函数和锁函数等。

### SQL语句

标准 SQL ：指符合国际标准的 SQL；

方言：各数据库支持的各自扩展功能。

##### SQL 语言分类

1. **DDL **（Data Definition Language）数据库定义语言：`CREATE、ALTER、DROP` 等语句；主要用于定义数据库/表结构、视图、索引和触发器等对象。主要由 `DBA` 数据库管理员使用。
2. **DML **（Data Manipulation Language）数据库操作语言：`INSERT、UPDATE、DELETE` 语句；用于插入、更新、删除表记录。
3. **DQL**（Data Query Language）数据库查询语言：`SELECT` 语句；用于查询表记录，最频繁的数据库操作。
4. **DCL**（Data Control Language）：数据库控制语言。主要用于控制用户的访问权限。其中：
   1. `GRANT`：增加用户权限；
     2. `REVOKE`：收回用户权限；
     3. `COMMIT`：确认对数据库中的数据进行的变更；
     4. `ROLLBACK`：取消对数据库中的数据进行的变更。
```
-- 允许远程连接的 IP 地址，“%”表示不限制连接的 IP
-- 123456 为用户密码
MySQL> grant all PRIVILEGES on <数据库名.表名> to root@'127.0.0.1/%'  identified by '123456' [WITH GRANT OPTION];

-- 开启MySQL的远程帐号，立即生效
FLUSH PRIVILEGES;
```

##### DDL 数据库/表结构操作

1. 创建：`CREATE` database **[IF NOT EXISTS]** <数据库名> / table <表名> 

  [[DEFAULT] CHARACTER SET <字符集名>] 
  [[DEFAULT] COLLATE <校对规则名 utf8_chinese_ci>];

2. 删除：`DROP` database [ **IF** **EXISTS** ] <数据库名> / table 表名;

3. 选择：`USE` <数据库名>;

4. 修改数据库：同创建；

5. 修改：`ALTER` TABLE <表名> [修改选项]：
  1. `ADD COLUMN` <新列名> <类型> [约束条件] [FIRST | after <已存在的列名>]
  2. `CHANGE COLUMN` <旧列名> <新列名> <新列类型不能为空>
  3. `ALTER COLUMN` <列名> { `SET DEFAULT` <默认值> | DROP DEFAULT }
  4. MODIFY COLUMN <列名> <**类型**>
  5. `DROP COLUMN` <列名>
  6. `RENAME TO` <新表名>
  7. CHARACTER SET <字符集名>
  8. COLLATE <校对规则名>

6. 修改存储引擎：ALTER TABLE <表名> ENGINE=<存储引擎名>;

```
-- 如果数据库中存在user_accounts表，就从数据库中删除
DROP TABLE IF EXISTS `user_accounts`;

-- 创建数据库表
CREATE TABLE `user_accounts` (
  `id`  int(100) unsigned NOT NULL AUTO_INCREMENT primary key,
  `password`  varchar(32) NOT NULL DEFAULT '' COMMENT '用户密码',
  `reset_pwd` tinyint(32) NOT NULL DEFAULT 0 COMMENT '用户类型：0-不需重置密码；1-需重置',
  `mobile`    varchar(20)  NOT NULL DEFAULT '' COMMENT '手机',
  `create_at` timestamp(6) NOT NULL DEFAULT CURRENT_TIMESTAMP(6),
  `update_at` timestamp(6) NOT NULL DEFAULT CURRENT_TIMESTAMP(6) ON UPDATE CURRENT_TIMESTAMP(6),
  -- 创建唯一索引，不允许重复
  UNIQUE INDEX idx_user_mobile(`mobile`)
)
ENGINE=InnoDB DEFAULT CHARSET=utf8
COMMENT='用户表信息';

SHOW CREATE TABLE <数据表名>;
desc/describe `sys_user`;
```

##### 数据类型的列属性/列约束

1. `PRIMARY KEY`：主键，不可空、不可重复；
2. `UNIQUE`：唯一索引（唯一约束），**可空**、不可重复，可在多个字段定义；主键和唯一约束的创建需依靠索引，没有已建好的索引，Oracle 会自动建立唯一索引。
3. `AUTO_INCREMENT`：自动增长约束，必须为索引（主键或 `unique`），只能用于一个字段、不可为空；只能是整数类型，默认从1开始，通过表属性 `auto_increment = x` 设置；
4. `FOREIGN KEY`：外键约束；
5. `DEFAULT` <默认值>：当前字段的默认值；
6. `NULL` 约束：表示当前列可为 null；
   - `NOT NULL` 约束：在添加数据时没有指定值，会报错；
7. `CHECK`：检查约束；
8. `COMMENT`：注释；
9. 反引号` `` `用于区分MYSQL的保留字与普通字符、识别符，如用于表名、列名等，如 \`status\`；单引号` '' `、双引号用于字符串。

```
-- 在定义完列后直接用关键字指定约束
<字段名> <数据类型> 约束关键字/UNIQUE
ALTER TABLE <数据表名> ADD CONSTRAINT <约束名> UNIQUE(<列名>);
ALTER TABLE <数据表名> CHANGE COLUMN <字段名> <数据类型> DEFAULT <默认值>/NULL;
ALTER TABLE <表名> DROP INDEX <约束名>;
```

##### DQL SELECT 和约束

在表查询中，一律不要使用 `*` 作为查询的字段列表，需要哪些字段必须明确写明。 

1. 增加查询分析器解析成本；
2. 增减字段容易与 resultMap 配置不一致；
3. 无用字段增加网络消耗，尤其是 text 类型的字段；

```
-- 投影查询：只返回某些列
SELECT 列1 别名1, 列2 别名2 FROM ...

-- FROM 子句
-- 多表查询/笛卡尔查询：每一行都两两拼在一起，行数为多表的乘积，结果集可能非常巨大
SELECT
    s.id sid,
    s.name,
    s.score,
    c.id cid,
    c.name cname
FROM students [AS] s, classes [AS] c
WHERE s.gender = 'M' AND c.id = 1;
[GROUP BY <group>
[HAVING <expression> [{<operator> <expression>}…]]
[ORDER BY <order>]
[LIMIT[<offset>,] <row count>]

-- WHERE 子句：运算符
and, or, not, xor：返回NULL、0、1
&&, ||, !,
<=, <, >=, >, 
=, !=/<>, <=>
    1. =表示比较两个值是否相等，但不能用于比较NULL；
    	NULL=NULL 的返回结果是 NULL，而不是 true;
    2. <=>表示安全的等于；不同于=，当比较的两个值相等或都为 NULL 时返回 true;
    	当一个操作数为 NULL 时，其返回值为 0 而不为 NULL;
    	NULL<=>NULL 的返回结果是 1(true);
    3. NULL<>NULL 的返回结果是 false;
    4. NULL<>1 的返回结果是 true;
is [not] null，更推荐ISNULL()
[not] between and：包括起始值和终止值
[not] like [BINARY区分大小写]："%"代表任何长度的字符串，不能匹配 NULL，"_"代表单个字符
[not] in ... ：尽量不用
is [not] ture/false/unknown：检验某个值的真假
... [NOT] EXISTS

-- HAVING 条件子句：类似where，过滤分组，对分组后/查询结果再次过滤，可用聚合函数、字段别名。

-- 排序子句
ORDER BY 首选排序字段/别名 排序方式（默认升序ASC/降序DESC） [二次排序字段/别名 ,排序方式] ...

-- LIMIT 限制结果数量子句
LIMIT <记录数> OFFSET <初始位置>
等价于 LIMIT <[初始位置,] 记录数>：初始位置由0开始计数，默认为0

-- 聚合函数、聚合查询
-- count 返回不同的非NULL值数目：
	count(*)：统计值不为 NULL 的行；
    count(列名)：不统计此列为 NULL 值的行，无结果返回0；
	count(distinct col)：计算该列除 NULL 外的不重复行数；
    count(distinct col1 , col2)：如果其中一列全为 NULL，即使另一列有不同的值，也返回为 0。

-- sum 求和，无结果或全为NULL时返回NULL，需注意 NPE 问题。下同
-- avg 求平均值
-- max/min 求最大/小值，不限于数值类型

SELECT COUNT(*/id) 聚合列别名 FROM ...
-- 分组聚合子句，得到N行结果<class_id, num>
    SELECT COUNT(*) num 
    FROM students 
    GROUP BY class_id;
-- 只支持分组的列，按class_id, gender分组:
    SELECT class_id, gender, COUNT(*) num 
    FROM students 
    GROUP BY class_id, gender;
-- 按性别分组，拼接name
    SELECT `sex`, GROUP_CONCAT(name) 
    FROM tb_students_info 
    GROUP BY sex;

-- DISTINCT, ALL 选项：去除重复记录
SELECT DISTINCT name,age FROM student; -- name不同、age相同不统计？
SELECT COUNT(DISTINCT name,age) FROM student;

-- AS 语法 用于为表或列(字段)提供临时名称(别名)。
select t1.name from table_1 as t1, table_2 as t2 where t1.id = t2.id;
-- 为子查询结果集指定别名
SELECT * FROM (SELECT * FROM result) AS Temp;

-- group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。
```

连接查询：对多个表进行 JOIN 运算，先确定一个主表作为结果集，然后选择性地“连接”其他表的行。

1. 内连接 `[INNER] JOIN`：
2. 外连接 `OUTER JOIN`
  1. `LEFT [OUTER] JOIN`：必须返回左边表的记录，右表可能返回 null；
  2. `RIGHT [OUTER] JOIN`
  3. `FULL [OUTER] JOIN`：取并集，彼此没有对应的值为 null。
3. `cross join`：结果是笛卡尔积，就是第一个表的行数乘以第二个表的行数。

`on 和 where` 条件的区别：on是 join on 的条件，先运行生成临时表，再根据 where 筛选；

 1. `on` 条件在**生成**临时表时使用，条件不为真也会返回左表中的记录。不管 on 中的条件是否为真，都会返回左边表中的记录。
 2. `where` 条件是在临时表**生成好后**，再对临时表进行**过滤**。这时已没有 `left join` 的含义（必须返回左边表的记录），条件不为真的就全部过滤掉。

`union VS union all`：都用于合并两个或多个 SELECT 语句的结果集。

1. `union`：取唯一值，记录没有重复；进行表连接后会筛选掉重复的记录，Union All 不去除重复记录。
2. `union all`：直接连接，取到的是所有值，记录可能有重复；

##### DML 增删改

返回 `WHERE` 条件匹配的行数及操作的行数。

```
INSERT [INTO] `user_info` [name, age] VALUES ("Tom", 21), ("Jack", 13);
INSERT [INTO] `user_info` name="Tom", age=21;

-- 插入，如果已存在则更新
INSERT INTO students (id, name, gender, score) VALUES (1, '小明', 'F', 99) ON DUPLICATE KEY UPDATE name='小明', gender='F', score=99;

DELETE FROM user_info WHERE ...

UPDATE user_info 
SET age=22, score=score+10 
WHEN name="Tom" and score<80;
```

##### drop、delete 与 truncate 区别

1. 用法不同：
   1. `drop table 表名`（删除表结构）： 释放表占用的空间。
   2. `truncate table 表名`（清空表中数据） : 用于删除表内的数据和索引，但不删除表本身。把自增值重置和索引恢复到初始大小等。
   3. `delete from 表名 where 列名=值`（删除某些行的数据） : 不加 where 子句同`truncate table 表名`。

2. 属于不同的数据库语言：
   1. `truncate` 和 `drop` 属于 DDL语句，原数据不放到 `rollback segment` 中，操作立即生效，不能回滚，操作不触发 trigger。有可能造成事故，故不建议使用。
   2. `delete` 是 DML 语句，操作会放到 `rollback segement` 中，事务提交后才生效。
   3. `DELETE` 删除数据后，配合事件回滚可找回数据；`TRUNCATE` 不支持事务的回滚，数据删除后无法找回。
3. 执行速度不同：
   - 一般来说：`drop > truncate > delete`。
   - `delete`命令执行时会产生数据库的`binlog`日志，逐行一条一条删除记录，因此比`truncate`慢，好处是方便数据回滚恢复。

##### SQL查重和去重

[在几千条记录里，如何用SQL语句删除掉重复的?](http://www.xiangguo.li/sql_and_nosql/2015/01/01/sql)

```
-- 查找表中多余的重复记录，重复记录是根据单个字段（peopleId）来判断
select * from people 
where peopleId in (select peopleId 
                   from people 
                   group by peopleId 
                   having count(peopleId) > 1)

-- 删除表中多余的重复记录，重复记录是根据单个字段（peopleId）来判断，只留有rowid最小的记录
delete from people 
where peopleId in (select peopleId from people group by peopleId having count(peopleId) > 1)
and rowid not in (select min(rowid) from people group by peopleId having count(peopleId) > 1)

-- 查找表中多余的重复记录（多个字段）
select * from vitae a
where (a.peopleId,a.seq) 
in (select peopleId,seq 
    from vitae group by peopleId,seq 
    having count(*) > 1)

-- 删除表中多余的重复记录（多个字段），只留有rowid最小的记录
delete from vitae a
where (a.peopleId,a.seq) in (select peopleId,seq from vitae 
                             group by peopleId,seq having count(*) > 1) 
           and rowid not in (select min(rowid) from vitae 
           					 group by peopleId,seq having count(*) > 1)

-- 查找表中多余的重复记录（多个字段），不包含rowid最小的记录
select * from vitae a
where (a.peopleId,a.seq) in (select peopleId,seq from vitae 
                             group by peopleId,seq 
                             having count(*) > 1) 
           and rowid not in (select min(rowid) from vitae 
                             group by peopleId,seq 
                             having count(*) > 1)
```

##### 删除表前1W行数据

1. 直接 `delete from T limit 10000`；
   - 单条语句执行时间过长，会导致长事务，导致锁的时间变长、主从延迟等问题。
2.  在一个连接中循环执行20次 `delete from T limit 500`；
   - 多个短事务串行执行，每次短暂执行就释放锁资源，相对更好一些；可优化为第3种并发执行。
3. **在20个连接中并发（同时）执行** `delete from T limit 500`；
   - 20个连接并发delete且条件一样，会人为导致锁冲突；但如果能将1W条数据先查出来，分片后分配给20个连接，通过id=xxx精确删除，各连接就不会相互竞争。

### 高性能优化

##### SQL 优化

1. 索引
2. 分库分表

##### 基本设计规范

- [数据库设计的重要性和设计原则](https://yq.aliyun.com/articles/131756)

##### 数据库、表、字段设计规范

1. 可读性原则：用下划线分隔字段等；
2. 表意性原则：表名应能体现其存储内容；临时库表必须以 `tmp_` 为前缀、以日期为后缀，备份表必须以 `bak_` 为前缀、以时间戳为后缀；
3. 长名原则：少用缩写；
4. 所有存储相同数据的列名和列类型必须一致；
5. 尽量控制单表数据量的大小在 500 万以内。过大会造成修改表结构、备份、恢复问题。可用历史数据归档（应用于日志数据），分库分表（应用于业务数据、单表行数超过 500 万行或单表容量超过 2GB时）等手段；
6. 冷热数据分离，减小表的宽度。减少磁盘 IO，保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大，会消耗更多的 IO）；
7. 尽可能把所有列定义为 NOT NULL；

##### 索引设计规范

- 建议单张表索引不超过 5 个；
- 选用 `WHERE` 从句或 `ORDER BY、GROUP BY、DISTINCT` 中的字段；

##### SQL开发规范

##### 数据库操作行为规范

- 避免使用**子查询**，会产生大量的临时表也没有索引，消耗过多的 CPU 和 IO 资源，对查询性能的影响大。
  - 子查询在 in 子句中，且为简单 SQL（不包含 union、group by、order by、limit 从句)）时,可优化为 join 关联查询。
- WHERE 从句中禁止对列进行函数转换和计算，导致无法用索引；

### 存储引擎

 存储引擎：如何存储数据并建立索引，更新、查询数据等技术的实现方法。

##### InnoDB 引擎

1. 行级锁：`MyISAM` 只有表级锁（对整张表加锁，不利于并发写），而 `InnoDB` 支持**行级锁和表级锁**（**高并发**下性能更好），支持**MVCC**（行级锁的一个升级）。
2. `InnoDB` 支持**事务**：有提交、回滚和崩溃恢复能力；用于计费或财务系统等对数据准确性要求比较高的；
3. `InnoDB` 支持**外键**；支持集群索引；

##### MyISAM 引擎

1. 选择密集型的表。最突出的优点是在筛选大量数据时非常迅速。
2. 插入密集型的表。批量插入速度快。并发插入特性允许同时选择和插入数据。如：管理邮件数据、日志记录系统（处理用户的登录日志、操作日志、Web服务器日志）等。
3. 支持全文索引；数据可压缩；

### 索引

索引：是一种用于快速查询和检索数据的数据结构，相当于目录的作用。实质上是一张描述索引列的列值与原表中记录（行）间一 一对应关系的有序表。

- 优点：大大加快数据检索速度；

- 缺点 ：创建和维护索引耗时间和空间。当对表中的数据增删改时，需同时修改索引，降低 SQL 执行效率。

索引的效率取决于索引列的值是否散列，即该列的值如果越互不相同，那么索引效率越高。

常见的索引结构有: `B` 树， `B+` 树和 `Hash` 表。

##### 索引的数据结构

##### Hash表

哈希表：是键值对的集合，用**哈希算法**通过键（key）即可快速取出对应的值（value）。缺点：

1. 哈希冲突：
   - JDK1.8 前 `HashMap` 用链地址法；
   - JDK1.8 后 `HashMap` 用红黑树；
2. 最大缺点是 Hash 索引不支持顺序和范围查询，hash 表存储的是无序数据，范围查找时需遍历，比较耗费时间。
3. 将所有的数据文件添加到内存，比较耗费内存空间。

##### B-Tree/多路平衡查找树

二叉树及其变种的其他树都不能支撑索引的需求，原因是插入数据的性能较低，且树的深度无法控制， 过深造成 IO 次数变多，影响读取数据的效率。

`B` 树 VS `B+` 树：

1. 节点：`B` 树的所有节点存放键和数据，而 `B+` 树只有叶子节点存放 key 和 data，其他内节点只存放 key。
2. 叶子节点：`B` 树的叶子节点是独立的；`B+` 树的叶子节点有引用链指向相邻的叶子节点。
3. 查找：`B` 树的检索相当于对节点的关键字做二分查找，可能不到叶子节点就找到；而 `B+` 树的查找是从根节点到叶子节点。

##### 索引的存储方式 / 索引类型

1. 聚集索引：索引结构和数据一起存放。`MyISAM` 中索引文件和数据文件是分离的，对于 `InnoDB` 引擎表来说，该表的索引（B+树、表数据文件）的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。
   - 优点：查询速度非常快，多叉平衡树叶子节点都是有序的，定位到索引的节点，就相当于定位到了数据。
   - 缺点：依赖于有序的数据；更新代价大。
   - 分类：
     - 主键索引：索引的 key 是数据表的主键。
2. 非聚集索引：索引结构和数据分开存放。叶节点 data 域存储的数据是主键的值而不是地址，用来定位主键的位置。如二级索引/辅助索引：
   - 最大缺点：可能会二次查询（回表)），当查到索引对应的指针或主键后，可能还需再到数据文件或表中查询。
   - 分类：
     1. 唯一索引：如身份证号、邮箱等；根据业务要求，不宜作为主键但有唯一性约束；可为NULL；
     2. 普通索引：
     3. 前缀索引：用于字符串类型；
     4. 全文索引：用于检索大文本数据中关键字的信息，搜索引擎数据库；
3. 覆盖索引：索引包含/覆盖所有需**查询**的字段的值，避免回表。相当于目录。

##### MySQL添加索引

> 1. 
>
> 2. 除了索引外，有过哪些SQL优化方面的经验？如分库分表，或通过执行计划查看SQL的优化点。最好是能结合做的实际项目来讲。

```
CREATE <索引名> ON <表名> (<列名> [<长度>] [ ASC | DESC]);
CREATE TABLE(...
KEY | INDEX | UNIQUE INDEX [<索引名>] [<索引类型>] (<列名>,…)
);

SHOW INDEX FROM <表名> [ FROM <数据库名>];
DROP INDEX <索引名> ON <表名>;

-- 1. 添加 主键索引
ALTER TABLE `table_name` ADD PRIMARY KEY ( `col` )

-- 2.添加 唯一索引
ALTER TABLE `table_name` ADD UNIQUE uni_name ( `col` )
-- 也可只对某一列添加唯一约束而不创建唯一索引：
ALTER TABLE students ADD CONSTRAINT uni_name UNIQUE (name);

-- 3.添加 普通索引
ALTER TABLE `table_name` ADD INDEX index_name ( `col` )

-- 4.添加 全文索引
ALTER TABLE `table_name` ADD FULLTEXT ( `col`)

-- 5.添加多列索引
ALTER TABLE `table_name` ADD INDEX index_name ( `col1`, `col2` )
```

##### 建立和使用索引的时机

在 `WHERE` 和 `JOIN` 语句中出现的列需建立索引，但也不完全如此：

选用 `WHERE` 从句或 `ORDER BY、GROUP BY、DISTINCT` 中的字段；

1. MySQL只对`<`，`<=`，`=`，`>`，`>=`，`BETWEEN`，`IN`使用索引；
2. 某些时候的`LIKE`也会使用索引；但在`LIKE`以通配符 `%和_` 开头做查询时，不会使用索引。如，`name like '123%'`会走索引；

### 事务

事务：用户定义的一个数据库操作序列，是逻辑上的一组操作；要么全都执行，要么全不执行。如 A 转出钱与 B 收到钱。

数据库事务：多条SQL 语句要么全部执行成功，要么全部不执行 。

```
-- 开始事务，显式事务
BEGIN; 或 START TRANSACTION;

UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;

COMMIT;

-- 回滚事务
ROLLBACK;
```

##### 事务的四大特性（ACID）

1. 原子性（`Atomicity`）：事务是最小的原子单位，（事务内的所有 SQL 作为一个原子单元执行），不可再分割。事务中的所有操作要么全部执行成功，要么全部执行失败。
   - MySQL InnoDB 引擎用 `undo log`（回滚日志）保证。
2. 一致性（`Consistency`）：事务执行前后，状态一致。如不管 A 、B 间如何转账，事务结束后两账户的总钱数与事务执行前一致，都是 5000。
3. 隔离性（`Isolation`）：当多个用户并发访问数据库时，多个并发事务间要相互隔离。如，操作同一张表时，数据库为每个用户开启的事务，不能被其他事务的操作所干扰。
   - 即要达到这么一种效果：对于任意两个并发的事务 T1 和 T2，在事务 T1 看来，T2 要么在 T1 开始前就已结束，要么在T1结束后才开始，这样每个事务都感觉不到有其他事务在并发地执行。
   - 数据库提供了多种隔离级别。
   - MySQL InnoDB 引擎通过 锁机制、MVCC 等。
4. 持久性（`Durability`）：一个事务被提交后，对数据库中数据的改变是持久的，即使数据库发生故障也不会丢失提交事务的操作。
   - MySQL InnoDB 引擎用 `redo log`（重做日志）保证。

##### 并发事务带的问题

> 副作用

1. 丢失（修改/）更新/脏写：当前事务的更新擦除（覆盖）了其它事务之前（未提交的）的更新；事务的任何隔离级别都一定不允许发生，对访问的数据加锁即可。
2. 脏读：一个事务读取到其它事务更新后（已修改）但未提交的数据，如果其它事务回滚该更新，则当前事务读的就是脏数据；
3. 不可重复读：在一个事务中，多次读同一数据，（在事务还未结束时，其它事务就修改了此数据），两次读取的数据可能不一致。
4. 幻读：在一个事务执行过程中，第一次未查询到某条记录，其它事务在此之后插入/删除并提交此条记录，再次按相同条件可查询到；即好像发生幻觉一样。

##### 隔离级别

事务隔离机制：并发处理带来的问题中，更新丢失可完全避免，由应用对数据加锁即可。脏读、不可重读度、幻读，其实都是数据库的一致性问题，必须由一定的事务隔离机制来解决。

<img src="assets/MySQL并发事务的问题及隔离级别.png" style="zoom:33%;" />

数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大。

1. `READ-UNCOMMITTED`（读取未提交）： 最低，允许读取尚未提交的数据变更；
   - 解决了丢失更新，可能导致脏读、不可重复读、幻读。
2. `READ-COMMITTED`（读取已提交）： 允许读取并发事务已提交的数据；
   - 解决了丢失更新、脏读，可能导致不可重复读、幻读。
3. `REPEATABLE-READ`（可重复读）： 对同一字段的多次读取结果都是一致的，除非数据是被事务本身所修改；MySQL InnoDB 存储引擎的**默认支持的隔离级别**。
   - 解决了丢失更新、脏读、不可重复读，可能导致幻读。
4. `SERIALIZABLE`（可序列化）： 最高，完全服从 ACID 。所有的事务依次逐个执行，事务间完全不可能产生干扰；串行执行，效率会大大下降。
   - 解决了丢失更新、脏读、不可重复读、幻读。

```
SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;
```

### 锁机制

##### 表锁、行锁、页锁

```
-- 锁定
	LOCK TABLES tbl_name [AS alias]
-- 解锁
    UNLOCK TABLES
```

##### InnoDB 锁算法

##### InnoDB的3种行锁定方式

### SQL语句在MySQL中的执行过程

MySQL 主要分为：

-  Server 层：主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（bin log，所有执行引擎都可共用），redo log 只有 InnoDB 有。
- 引擎层：主要包括 `MyISAM、InnoDB、Memory` 等。

执行流程：

- 查询语句：权限校验（如果命中缓存）=> **查询缓存** => 分析器 => 优化器 =>权限校验 => 执行器 =>存储引擎；
- 更新语句：分析器 => 权限校验 => 执行器 => 引擎 => redo log（prepare 状态） => bin log => redo log（commit状态）

### 视图

视图：是一种虚拟的表，数据库中只存定义，数据来自所引用的真实表。

```
CREATE VIEW <视图名> AS <SELECT语句>;
CREATE VIEW v_stu_info (s_id, s_name, d_id, s_age)
AS SELECT id,name,dept_id,age FROM tb_stu_info;
DESCRIBE 视图名;
```

### 存储过程

存储过程：是一组为了完成特定功能的 SQL 语句集合，加了逻辑控制语句。更偏向于业务逻辑。

- 优点：在业务比较复杂时非常实用，如一个操作需写一大串 SQL 语句。存储过程一旦调试完成通过后就能稳定运行；比单纯 SQL 语句执行要快，因为存储过程是预编译过的。

- 缺点：存储过程难以调试和扩展，没有移植性，消耗数据库资源。禁止使用。

```
CREATE PROCEDURE <过程名> ( [过程参数[,…] ] ) <过程体>
[过程参数[,…] ] 格式
[ IN | OUT | INOUT ] <参数名> <类型>
```

### 触发器

```
create trigger <触发器名称>  
{ before | after}         -- 之前或之后触发
insert | update | delete  -- 指明激活触发程序的语句的类型  
on <表名>                  -- 操作哪张表  
for each row              -- 触发器的执行间隔，通知触发器每隔一行执行一次动作，而不是对整个表执行一次。  
<触发器SQL语句>
```

### 数据备份与还原

- 热备（Hot Backup）
- 冷备（Cold Backup）
- 温备（Warm Backup）

### 三大日志

1. binlog（归档日志）：是物理日志，记录"在某个数据页上做了哪些修改"。用于数据备份；
2. redo log（重做日志）：InnoDB独有；用于MySQL 实例挂了或宕机、崩溃恢复；
3. undo log（回滚日志）：发生异常时，对已执行的操作进行回滚。用于实现MVCC。

结合事物的四大特性

1. MySQL是怎么保证数据不丢的？
2. 为什么不直接写数据文件而是写redo log？

### SQL注入

##### SQL 注入方式

- 最常见的是：通过网页输入框（<input> 、<textarea> 标签等）将恶意 SQL 代码提交给服务器。将 userName 参数拼接到 SQL 语句中，从而构建 SELECT 查询，从数据库中获取当前用户的所有信息。

##### 防止 SQL 注入

1. Web 防火墙可检测和阻止最基本的 SQL 注入；
2. 传参用参数占位符 `#{}`，尽量避免用变量占位符 `${}`；
3. 检测用户输入的内容。永远不要信任用户提供的数据，仅在校验通过后才将数据提交给数据库。
  1. 在页面输入参数时进行字符串检测和提交时进行参数检查、用正则表达式过滤参数中的特殊符号等。
  2. 用户输入的 SQL 参数严格使用参数绑定或 METADATA 字段值限定，禁止字符串拼接 SQL 访问数据库。

### 参考

- [MySQL教程：MySQL数据库学习宝典（从入门到精通）](http://c.biancheng.net/mysql/)
- [廖雪峰SQL教程](https://www.liaoxuefeng.com/wiki/1177760294764384)

## Redis 缓存数据库

Redis：用 C 语言开发的数据库，数据存在内存中（即内存数据库），读写速度非常快。

> QPS（Query Per Second）：服务器每秒可执行的查询次数。

### 用途

用于：

1. 数据缓存：处理大量数据的高访问负载；用 Redis 缓存数据库的目的：主要是为了提升用户体验、及应对更多的用户。
   - 高性能：缓存数据的处理流程。如用户第一次访问数据库中的某些数据的话，从硬盘中读取，比较慢。用户访问的数据属于高频数据且不会经常改变的话，则将该数据放入缓存，用户下一次再访问时可直接从缓存中获取。
   - 高并发：直接操作缓存能承受的数据库请求数量远远大于直接访问数据库的，所以可考虑把数据库中的部分数据转移到缓存中，这样用户的一部分请求会直接到缓存而不用经过数据库。
2. 分布式锁：基于 Redisson 实现分布式锁；
3. 限流 ：通过 Redis + Lua 脚本的方式来实现限流；
4. 消息队列：Redis 自带的 list 数据结构可作为简单的队列使用。
   - Redis 5.0 中增加的 Stream 类型的数据结构更适合用来做消息队列，类似于 Kafka。支持：
     1. 发布 / 订阅模式；
     2. 按照消费者组进行消费、主题；
     3. 消息持久化（ RDB 和 AOF）；
     4. ACK 机制。
   - 推荐较成熟的一些消息队列，如 RocketMQ、Kafka 等。

### 分布式缓存常见技术选型方案

分布式缓存：主要解决单机缓存的容量受服务器限制、且无法保存通用信息的问题。因为本地缓存只在当前服务里有效，如果部署了两个相同的服务，两者间的缓存数据无法共享。

##### Redis 和 Memcached

**共同点** ：

1. 都是基于内存的数据库，一般都用来当做缓存使用；
2. 都有过期策略；
3. 两者的性能都非常高；

**区别** ：

1. Redis 支持更丰富的**数据类型**（更复杂的应用场景），不仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2. Redis 支持数据的**持久化**，有灾难恢复机制，可将内存（缓存）中的数据持久化到磁盘中，重启时可再次加载使用。而 Memcached 把数据全部存在内存中。
3. [内存管理](#内存管理)：Redis 在**服务器内存**用完后，可将不用的数据放到磁盘上。Memcached 直接报异常。
5. Redis 使用**[单线程](#单线程模型)的多路 IO 复用模型**（Redis 6.0 引入了多线程 IO ）。Memcached 是多线程，非阻塞 IO 复用的网络模型。
8. Redis **[过期数据的删除策略](#过期数据的删除策略)**同时用了惰性删除与定期删除。Memcached 只用了惰性删除。
6. Redis 支持**发布订阅模型、Lua 脚本、事务**等功能、更多编程语言。而 Memcached 不支持。
7. Redis 原生支持 cluster 模式的。Memcached 没有原生的**集群**模式，需依靠客户端来实现往集群中分片写入数据。

### 5大基础数据类型

5大基础数据类型及应用场景

1. `string`：简单的 key-value 类型。

   - 常用命令： `set/get/del, mset, setex, strlen, exists, incr/decr, expire, ttl` 等。
   - 应用场景： 常用在需计数的场景，如用户的访问次数、热点文章的点赞转发数等。

2. `list`：即双向链表。支持反向查找和遍历。

   - 常用命令：`rpush/rpop, lpush/lpop, lrange, llen` 等。
   - 应用场景：实现队列、栈，发布与订阅、消息队列、慢查询。

   <img src="assets/redis-list.png" alt="redis list" style="zoom: 67%;" />

3. `hash`：类似于 JDK1.8 前的 HashMap，内部实现也差不多（数组 + 链表）。是一个 string 类型的 field 和 value 的映射表。

   - 常用命令： `hset/hmset/hget, hgetall, hexists, hkeys, hvals` 等。
   - 应用场景：特别适合用于存储对象。

4. `set`：类似于 HashSet 。提供了判断某个成员是否在 set 集合内的重要接口，轻易实现交、并、差集的操作。如：共同关注就是求交集。

   - 常用命令： `sadd/spop, smembers, sismember, scard（长度）, sinterstore（交集）, sunion` 等。
   - 应用场景：存放不重复的数据及需获取多个数据源交集和并集等场景

5. `sorted set`：比 set 增加了一个权重参数 `score`，使集合中的元素能按 score 进行有序排列，还可通过 score 的范围来获取元素的列表。有点像 HashMap 和 TreeSet 的结合体。

   - 常用命令： `zadd, zcard, zscore, zrange, zrevrange, zrem` 等。
   - 应用场景： 需对数据根据某个权重进行排序的场景。如实时礼物排行等。

6. `bitmap`：存储连续的二进制数字（0 和 1）。只需一个 `bit` 位来表示某个元素对应的值或状态，key 就是对应元素本身。 8  bit 可组成一个 byte，所以会极大的节省储存空间。

   - 常用命令： `setbit/getbit, bitcount, bitop`等
   - 应用场景： 需保存状态信息（如是否签到、是否登录...）并进一步进行分析的场景。
     1. 用户行为分析：分析喜好，需研究点赞过的内容；
     2. 统计活跃用户：用时间作为 key，用户 ID 为 offset，如果当日活跃过就设置为 1；
     3. 获取或统计用户在线状态：只需要一个 key，用户 ID 为 offset，如果在线就设置为 1，不在线就设置为 0。

> 见 [Redis 常见命令的用法](https://github.com/Snailclimb/JavaGuide/blob/main/docs/database/redis/redis-questions-01.md#redis-%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)

### 线程模型

##### 单线程模型

Redis 基于 Reactor 模式的**文件事件处理器**，以单线程方式运行，通过**I/O 多路复用程序** 来监听多个（客户端连接）套接字（Socket），将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。

- 文件事件分派器（将 socket 关联到相应的事件处理器）；
- IO 多路复用程序（支持多个客户端连接的关键）：不需额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗；
- 多个 Socket（客户端连接）；
- 事件处理器（命令请求处理器、命令回复处理器、连接应答处理器）；

用 I/O 多路复用机制同时监听多个文件描述符的可读和可写状态，一旦收到网络请求就会在内存中快速处理。由于绝大多数的操作都是纯内存的，所以**处理速度非常快**。

<img src="assets/redis事件处理器.png" alt="img" style="zoom:45%;" />

##### 多线程

Redis 4.0 之前为什么不用多线程用单线程？

1. 更好的可维护性，方便开发和调试；单线程**编程容易**且更易维护；
2. 主要原因：Redis 的**性能瓶颈**不在 CPU （资源），主要在内存和网络（I/O操作）；使用多线程模型带来的性能提升并不能抵消开发和维护成本（可维护性低）；
3. 单线程模型（用 I/O 多路复用机制）也能并发处理来自客户端的多个连接，同时等待多个连接发送请求；
4. 多线程存在死锁、线程上下文切换等问题，甚至会影响性能。

Redis 6.0 之后为什么引入多线程？

1. 主要是为了提高网络 IO 读写性能（解决性能瓶颈）。
2. 充分利用多核。

> 默认禁用，需手动打开。

### 内存管理

##### 缓存数据设置过期时间

- 有助于缓解内存消耗：内存是有限的，如果缓存中的所有数据都一直保存，会有OOM。

```
> exp key 60 # 数据在 60s 后过期，expire 命令
(integer) 1
> setex key 60 value # 数据在 60s 后过期，用于string
OK
> ttl key # 查看数据还有多久过期
(integer) 56
```

##### Redis 判断数据过期

通过 过期字典（可看作是 hash 表）来保存数据过期的时间。键指向 Redis 数据库中的 key，值是一个 long long 类型的整数，保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。

##### 过期数据的删除策略

Redis 采用的是 **定期删除+惰性/懒汉式删除** 。

1. 惰性删除 ：只在取出 key 时才对数据进行过期检查；可能造成太多过期 key 没有被删除。
2. 定期删除 ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。

定期删除对内存更友好，惰性删除对 CPU 更友好。 

##### Redis 内存淘汰机制

>  4.0 版本后增加两种 LFU。

`volatile`：从已设置过期时间的数据集（server.db[i].expires）中，

1. `volatile-lru`（least recently used）：淘汰**最近最少使用**的数据。
2. `volatile-lfu`（least frequently used）：淘汰**最不常用**的数据
3. `volatile-ttl`：淘汰将要过期的数据。
4. `volatile-random`：任意选择数据淘汰。

`allkeys`：当内存不足以容纳新写入数据时，在键空间中，

1. `allkeys-lru`：移除最近最少使用的 key；最常用。
2. `allkeys-lfu`：移除最不常用的 key。
3. `allkeys-random`：从数据集（server.db[i].dict）中任意选择数据淘汰。
4. `no-eviction`：禁止驱逐数据，即新写入操作会报错。没人用。

### 持久化机制

Redis 持久化机制（怎么保证 Redis 挂掉之后再重启数据可进行恢复）

持久化数据：将内存中的数据写入到硬盘。

1. 重用数据（如机器故障、重启机器后恢复数据）；
2. 或为了防止系统故障而将数据备份到一个远程位置。 

##### 持久化方式

- 默认，RDB 持久化：通过创建快照来获得（存储在内存里的）数据在某个时间点上的副本。
- 只追加文件（append-only file, AOF）：每执行一条会更改 Redis 中数据的命令，就将该命令写入到内存缓存 `server.aof_buf` 中，然后再根据 `appendfsync` 配置来决定何时将其同步到硬盘中的 AOF 文件。

```
appendfsync always    # 每次有数据修改发生时都会写入AOF文件,严重降低速度
appendfsync everysec  # 每秒钟同步一次，显式地将多个写命令同步到硬盘，推荐
appendfsync no        # 让操作系统决定何时进行同步
```

##### AOF 重写

AOF 重写：通过读取数据库中的键值对来实现，程序无须对现有 AOF 文件进行任何读入、分析或写入操作。

1. 在执行 `BGREWRITEAOF` 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。
2. 当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。
3. 最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。

### 事务

> 不建议使用

##### 事务命令

1. `MULTI`命令：可输入多个命令，放到队列，当调用了 `EXEC` 命令再执行所有命令；
2. `DISCARD`命令：取消一个事务，清空事务队列中保存的所有命令；
3. `WATCH`命令：用于监听指定的键；当调用 `EXEC` 命令执行事务时，如果一个被 `WATCH` 命令监视的键被修改的话，整个事务都不会执行，直接返回失败。

```
> MULTI #开始事务
OK
> SET USER "Guide哥" #命令入队(批量操作 Redis 的命令，先进先出（FIFO）的顺序执行)
QUEUED
> GET USER
QUEUED
> EXEC #执行事务
1) OK
2) "Guide哥"
```

**不满足原子性（和持久性）**

Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。且不支持回滚操作。不满足“要么全部完成，要么完全不起作用”。

### 管道

> 

### 集群

> 

### 性能优化

#### bigkey

`bigkey`：key 对应的 value 所占用的内存较大。如 string 类型的 value 超过 10 kb，复合类型的 value 包含的元素超过 5000 个（对于复合类型的 value，不一定包含的元素越多，占用的内存就越多）。

### 生产问题

##### 缓存穿透

缓存穿透、击穿：大量请求的 key 根本不存在于缓存中，导致请求（没有经过缓存）直接到数据库上。

解决方法：

- 参数校验：不合法的参数请求直接抛出异常信息返回给客户端。如查询的数据库 id 不能小于 0、传入的邮箱格式错误等；
- 缓存无效 key：如果缓存和数据库都查不到某个 key 的数据就写入 Redis 并设置过期时间，可解决请求的 key 变化不频繁的情况；
- 布隆过滤器：可非常方便地判断一个给定数据不存在于海量数据中（哈希函数）；
  - 把所有可能存在的请求的值都存放在布隆过滤器中，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。
  - 用于Redis、海量数据处理、缓存穿透的场景。

##### 缓存雪崩

- Redis 服务不可用：缓存在同一时间大面积失效，请求都直接落到数据库上，造成数据库短时间内承受大量请求。
  1. 采用 Redis 集群，避免单机出现问题整个缓存服务都无法使用；
  2. 限流，避免同时处理大量的请求。
- 热点缓存失效：被大量访问的数据在某一时刻大面积失效，请求都直接落到数据库上。
  1. 设置不同的缓存失效时间，如随机设置；
  2. 缓存永不失效。

### 缓存读写策略

##### Cache Aside Pattern（旁路缓存模式）

适合读请求较多的场景。

写请求：

1. 先更新 DB；
2. 然后直接删除 cache 。
  - 先删除 cache ，后更新 DB，可能会造成数据库和缓存数据不一致的问题。

读请求 :

1. 从 cache 中读取数据，读取到就直接返回；
2. cache中读取不到的话，就从 DB 中读取数据返回，再把数据放到 cache 中。

缺陷：

1. 首次请求数据一定不在 cache 的问题：可将热点数据提前放入cache 中。

2. 写操作较频繁导致cache中的数据会被频繁被删除，影响缓存命中率 。

解决办法：

- 数据库和缓存数据强一致场景 ：更新DB时同样更新cache，不过需加一个锁/分布式锁来保证更新cache时不存在线程安全问题。
- 可短暂地允许数据库和缓存数据不一致的场景 ：更新DB时同样更新cache，但给缓存加一个较短的过期时间，可保证即使数据不一致影响也比较小。

##### 保证缓存和数据库数据的一致性

如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：

1. 让缓存数据失效时间变短（不推荐，治标不治本） ：缓存会从数据库中加载数据。不适用先操作缓存后操作数据库的场景。
2. 增加 cache 更新重试机制（常用）： 如果 cache 服务当前不可用导致缓存删除失败，就隔一段时间重试。如果多次重试还是失败，可把当前更新失败的 key 存入队列中，等缓存服务可用后，再将缓存中对应的 key 删除即可。

[缓存和数据库一致性问题，看这篇就够了 - 水滴与银弹](https://mp.weixin.qq.com/s?__biz=MzIyOTYxNDI5OA==&mid=2247487312&idx=1&sn=fa19566f5729d6598155b5c676eee62d&chksm=e8beb8e5dfc931f3e35655da9da0b61c79f2843101c130cf38996446975014f958a6481aacf1&scene=178&cur_album_id=1699766580538032128#rd)

##### Read/Write Through Pattern（读写穿透）

服务端把 cache 视为主要数据存储，从中读写数据。cache 服务负责将此数据读取和写入 DB，从而减轻应用程序的职责。少见。

写（Write Through）：

1. 先查 cache，cache 中不存在，直接更新 DB。
2. cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（同步更新 cache 和 DB）。

读(Read Through)：

1. 从 cache 中读取数据，读取到就直接返回 。
2. 读取不到的话，先从 DB 加载，写入到 cache 后返回响应。

##### Write Behind Pattern（异步缓存写入）

和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。

但又有很大不同：Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，改为异步批量的方式来更新 DB。少见。